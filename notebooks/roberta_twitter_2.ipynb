{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if TensorFlow is using the GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Get the name of the GPU\n",
        "if tf.config.experimental.list_physical_devices('GPU'):\n",
        "    print(tf.config.experimental.list_physical_devices('GPU'))\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyrXfpQHnj37",
        "outputId": "ad96a263-f6d7-40ec-976b-0c18b5dafa7f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/TheZarif/disaster-tweets/raw/main/nlp-getting-started.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUeeC5JmtXFN",
        "outputId": "de9ec5c7-08ed-42d6-c4e4-b7b6fb7f807c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-29 01:08:50--  https://github.com/TheZarif/disaster-tweets/raw/main/nlp-getting-started.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TheZarif/disaster-tweets/main/nlp-getting-started.zip [following]\n",
            "--2023-11-29 01:08:50--  https://raw.githubusercontent.com/TheZarif/disaster-tweets/main/nlp-getting-started.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp-getting-started.zip’\n",
            "\n",
            "nlp-getting-started 100%[===================>] 593.11K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-11-29 01:08:50 (29.6 MB/s) - ‘nlp-getting-started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip nlp-getting-started.zip -d data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8wYUfL0t9q2",
        "outputId": "4422a2c4-2deb-46ed-fc80-e4eb2752ef81"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  nlp-getting-started.zip\n",
            "  inflating: data/sample_submission.csv  \n",
            "  inflating: data/test.csv           \n",
            "  inflating: data/train.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv(\"/content/data/train.csv\")\n",
        "df_test = pd.read_csv(\"/content/data/test.csv\")\n",
        "\n",
        "print('Training Set Shape = {}'.format(df_train.shape))\n",
        "print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\n",
        "print('Test Set Shape = {}'.format(df_test.shape))\n",
        "print('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alUtNfoRt_zZ",
        "outputId": "8aa5c364-7c64-40a7-d26d-c78403c3248a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Shape = (7613, 5)\n",
            "Training Set Memory Usage = 0.29 MB\n",
            "Test Set Shape = (3263, 4)\n",
            "Test Set Memory Usage = 0.10 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SPLIT=0.2"
      ],
      "metadata": {
        "id": "yGLA-1B6vTBp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_train[\"text\"]\n",
        "y = df_train[\"target\"]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=VAL_SPLIT, random_state=42)\n",
        "\n",
        "X_test = df_test[\"text\"]"
      ],
      "metadata": {
        "id": "c3gQFxYQuEWc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yYMVU-f7pbkL"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    preprocessed_text = []\n",
        "    for t in text.split():\n",
        "        if len(t) > 1:\n",
        "            t = '@user' if t[0] == '@' and t.count('@') == 1 else t\n",
        "            t = 'http' if t.startswith('http') else t\n",
        "        preprocessed_text.append(t)\n",
        "    return ' '.join(preprocessed_text)\n",
        "\n",
        "X_train = X_train['text'].apply(preprocess)\n",
        "X_val = X_val['text'].apply(preprocess)\n",
        "X_test = X_test.apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: type of X_train.to_list()[0]\n",
        "\n",
        "print(type(X_train.to_list()[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV5oowqlqqpf",
        "outputId": "8fd37169-9389-450f-af54-a27de9b1c899"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load tokenizer and model\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-2021-124m\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=2, from_pt=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evupA1dipHyy",
        "outputId": "e0f3d7de-e0a5-43df-b92a-ecdef421ec69"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',  # or 'val_accuracy'\n",
        "    patience=1,  # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Whether to restore model weights from the epoch with the best value of the monitored quantity\n",
        ")"
      ],
      "metadata": {
        "id": "0ePbJ9mipmA1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics = ['accuracy']\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "metadata": {
        "id": "B0cvprbbtD5U"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data\n",
        "encoded_inputs_dummy = tokenizer(X_train.head(20).to_list(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "encoded_inputs = tokenizer(X_train.to_list(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "encoded_inputs_val = tokenizer(X_val.to_list(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "encoded_inputs_test = tokenizer(X_test.to_list(), padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "# Extract input_ids and attention_mask\n",
        "X_train_process_dum = encoded_inputs_dummy[\"input_ids\"]\n",
        "attention_mask_dum = encoded_inputs_dummy[\"attention_mask\"]\n",
        "\n",
        "X_train_process = encoded_inputs[\"input_ids\"]\n",
        "attention_mask = encoded_inputs[\"attention_mask\"]\n",
        "\n",
        "X_val_process = encoded_inputs_val[\"input_ids\"]\n",
        "attention_mask_val = encoded_inputs_val[\"attention_mask\"]\n",
        "\n",
        "X_test_process = encoded_inputs_test[\"input_ids\"]\n",
        "attention_mask_test = encoded_inputs_test[\"attention_mask\"]\n",
        "\n",
        "# If you have labels, ensure they are also tensors\n",
        "y_train_process_dum = tf.constant(y_train.head(20).to_list())\n",
        "y_train_process = tf.constant(y_train.to_list())\n",
        "y_val_process = tf.constant(y_val.to_list())"
      ],
      "metadata": {
        "id": "e__jSBgowJyk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x={\"input_ids\": X_train_process, \"attention_mask\": attention_mask},\n",
        "    y=y_train_process,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    validation_data=({\"input_ids\": X_val_process, \"attention_mask\": attention_mask_val},\n",
        "                     y_val_process),\n",
        "    callbacks=[early_stopping_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe-UT6RkwPmo",
        "outputId": "8741023b-8819-4b4f-ed9a-ace31e7161a0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "191/191 [==============================] - 137s 511ms/step - loss: 0.4362 - accuracy: 0.8144 - val_loss: 0.3741 - val_accuracy: 0.8510\n",
            "Epoch 2/10\n",
            "191/191 [==============================] - 95s 497ms/step - loss: 0.3252 - accuracy: 0.8724 - val_loss: 0.3932 - val_accuracy: 0.8483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions = model.predict({'input_ids': X_test_process, 'attention_mask': attention_mask_test})\n",
        "probabilities = tf.nn.softmax(predictions.logits, axis=-1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqFH2mbduhzr",
        "outputId": "796c1de1-2014-40cf-85d3-9943efbcee1f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102/102 [==============================] - 18s 149ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['target'] = predicted_labels"
      ],
      "metadata": {
        "id": "kTwqjZ5b4Rfq"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZfJlUF-49oO",
        "outputId": "e2322a1f-22ff-4c68-f834-c9309953678e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[['id', 'target']].to_csv('/content/drive/My Drive/disaster-tweets/twitter-roberta.csv', index=False)"
      ],
      "metadata": {
        "id": "mzbfEg7W5gnS"
      },
      "execution_count": 58,
      "outputs": []
    }
  ]
}